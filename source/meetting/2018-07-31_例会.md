# MDW模块设计

* 版本1
1. spark任务单个job的运行情况、描述、整体流程、数据量
2. 规则。
3. 数据结构
4. 血缘，从·数据源头开始的一个数据流向，规则。
5. 分析结果，存储路径

* 版本2
1. 计划任务,全局任务管控，任务关系的一个说明
2. 历史数据清理

* 版本3
1. etl的元数据部分：包括数据源的配置，以及转换验证规则。
2. 表之间关系应该在hive基础上创建。
3. 存储格式，追加方式。
4. 表结构，应该是读取的。
5. 全局的检索，列字段


* kylo的可用性。
1. 学习成本？
2. 自定义功能。

* 总结
1. 数据结构和血缘。wherehouse
2. job监控 flume+es
3. 流程定制 ooizen+spark+shell
4. 验证规则 java
5. etl sqoop+flume
6. dashboard
7. 周报日报

## 大家相互培训一下
ooizen+sqoop+flume+nifi+es+wherehouse
